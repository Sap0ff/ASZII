{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Практическое задание 6.\n","\n","---\n","\n","\n","\n","Выполнил студент группы ББМО-02-23 Сапов.А.Д."],"metadata":{"id":"4ynCws849y0j"}},{"cell_type":"markdown","source":["**Этап 1**. Загрузка и создание двух различных моделей:"],"metadata":{"id":"fpQVxWoOE8kZ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ip8trjHS8G6t","outputId":"f25eec4d-8f33-475b-dd6a-74b2937cb666","executionInfo":{"status":"ok","timestamp":1741728228559,"user_tz":-180,"elapsed":190316,"user":{"displayName":"Alexandr Sapov","userId":"13531385528974079526"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8796 - loss: 0.4317\n","Epoch 2/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9672 - loss: 0.1143\n","Epoch 3/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.0729\n","Epoch 4/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0560\n","Epoch 5/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0436\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - accuracy: 0.9149 - loss: 0.2869\n","Epoch 2/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - accuracy: 0.9837 - loss: 0.0531\n","Epoch 3/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9899 - loss: 0.0308\n","Epoch 4/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9942 - loss: 0.0188\n","Epoch 5/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9958 - loss: 0.0139\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.utils import to_categorical\n","# Загрузка данных MNIST\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","# Нормализация данных\n","train_images = train_images / 255.0\n","test_images = test_images / 255.0\n","# Преобразование меток в one-hot encoding\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","# Модель 1: Простая полносвязная нейронная сеть\n","model1 = Sequential([\n","  Flatten(input_shape=(28, 28)),\n","  Dense(128, activation='relu'),\n","  Dense(10, activation='softmax')])\n","# Компиляция модели\n","model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n","# Обучение модели\n","model1.fit(train_images, train_labels, epochs=5)\n","# Сохранение модели\n","model1.save('mnist_model(1).h5')\n","# Модель 2: Свёрточная нейронная сеть (CNN)\n","model2 = Sequential([\n","  Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n","  MaxPooling2D((2, 2)),\n","  Flatten(),\n","  Dense(128, activation='relu'),\n","  Dense(10, activation='softmax')\n","])\n","# Компиляция модели\n","model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n","# Обучение модели\n","model2.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=5)\n","# Сохранение модели\n","model2.save('mnist_model(2).h5')"]},{"cell_type":"markdown","source":["**Этап 2**. Реализация атаки FGSM на первую модель:"],"metadata":{"id":"FxAKCLoRC9HT"}},{"cell_type":"code","source":["import numpy as np\n","# Функция для реализации FGSM атаки\n","def fgsm_attack(image, epsilon, gradient):\n","  # Применение знака градиента к изображению\n","  perturbed_image = image + epsilon * np.sign(gradient)\n","  # Обрезка значений, чтобы они оставались в пределах [0,1]\n","  perturbed_image = np.clip(perturbed_image, 0, 1)\n","  return perturbed_image\n","# Вычисление градиента\n","def generate_adversarial_example(model, image, label, epsilon):\n","    # Превращаем изображение в формат, подходящий для модели\n","    image = tf.convert_to_tensor(image.reshape((1, 28, 28, 1)))\n","\n","    # Если label — это one-hot вектор, преобразуем его в индекс\n","    if len(label.shape) > 1 and label.shape[1] > 1:\n","        label = np.argmax(label)\n","    label = tf.convert_to_tensor(label)\n","\n","    with tf.GradientTape() as tape:\n","        tape.watch(image)\n","        prediction = model(image)\n","        loss = tf.keras.losses.categorical_crossentropy(label[None], prediction)\n","\n","    gradient = tape.gradient(loss, image)\n","\n","    # Применяем FGSM\n","    adversarial_image = fgsm_attack(image.numpy(), epsilon, gradient.numpy())\n","\n","    # Убедимся, что adversarial_image имеет правильную форму\n","    return np.reshape(adversarial_image, (28, 28, 1))\n","\n","def generate_adversarial_dataset(model, images, labels, epsilon):\n","    adversarial_images = []\n","    for i in range(len(images)):\n","        adv_image = generate_adversarial_example(model, images[i], labels[i], epsilon)\n","        adversarial_images.append(adv_image.reshape(28, 28))\n","\n","    adversarial_images = np.array(adversarial_images)\n","\n","    # Проверка формы\n","    print(\"Shape of adversarial_images:\", adversarial_images.shape)\n","\n","    return adversarial_images\n","\n","\n","# Генерация противоречивых примеров для первой модели\n","epsilon = 0.1\n","adversarial_images_model1 = generate_adversarial_dataset(model1, test_images, test_labels, epsilon)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UxFSUIbKC_-F","outputId":"97c68da7-a2bb-44fb-87d9-7c01d92c8c77","executionInfo":{"status":"ok","timestamp":1741728329718,"user_tz":-180,"elapsed":85210,"user":{"displayName":"Alexandr Sapov","userId":"13531385528974079526"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of adversarial_images: (10000, 28, 28)\n"]}]},{"cell_type":"markdown","source":["**Этап 3**. Оценка противоречивых примеров на обеих моделях:"],"metadata":{"id":"U2_KhE07DWWQ"}},{"cell_type":"code","source":["# Оценка первой модели на противоречивых примерах\n","loss1, acc1 = model1.evaluate(adversarial_images_model1, test_labels)\n","print(f'Accuracy of model1 on adversarial examples: {acc1}')\n","\n","# Оценка второй модели на противоречивых примерах (перенос атаки)\n","adversarial_images_model1_reshaped = adversarial_images_model1.reshape(-1, 28, 28, 1)\n","loss2, acc2 = model2.evaluate(adversarial_images_model1_reshaped, test_labels)\n","print(f'Accuracy of model2 on adversarial examples from model1: {acc2}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HPyYV7gWDXpr","outputId":"cbd35a45-b199-48a0-c9c3-f2e88ff33a5b","executionInfo":{"status":"ok","timestamp":1741728345162,"user_tz":-180,"elapsed":2292,"user":{"displayName":"Alexandr Sapov","userId":"13531385528974079526"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0832 - loss: 6.5517\n","Accuracy of model1 on adversarial examples: 0.11379999667406082\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9582 - loss: 0.1381\n","Accuracy of model2 on adversarial examples from model1: 0.965499997138977\n"]}]},{"cell_type":"markdown","source":["**Этап 4**. Анализ переносимости атак:"],"metadata":{"id":"sjTIkBjkDbGf"}},{"cell_type":"code","source":["adversarial_images_model2 = generate_adversarial_dataset(model2,\n","test_images.reshape(-1, 28, 28, 1), test_labels, epsilon)\n","\n","# Оценка первой модели на противоречивых примерах второй модели\n","loss3, acc3 = model1.evaluate(adversarial_images_model2.reshape(-1, 28,\n","28), test_labels)\n","print(f'Accuracy of model1 on adversarial examples from model2: {acc3}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XCFFMKDEDe6G","outputId":"7490c15d-bfd7-4118-b23d-20dab6775826","executionInfo":{"status":"ok","timestamp":1741728472999,"user_tz":-180,"elapsed":125415,"user":{"displayName":"Alexandr Sapov","userId":"13531385528974079526"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of adversarial_images: (10000, 28, 28)\n","\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9237 - loss: 0.2535\n","Accuracy of model1 on adversarial examples from model2: 0.9359999895095825\n"]}]},{"cell_type":"markdown","source":["**Вывод**\n","\n","В практической работе было исследовано влияние атаки по переносу, при которой противоречивые примеры, сгенерированные для одной модели, использовались для атаки на другую.\n","\n","Точность первой модели сократилась с 98% до 12%, что указывает на её высокую уязвимость к данной атаке. В то же время точность второй модели снизилась с 99% до 96%, демонстрируя значительно более устойчивый результат.\n","\n","Кроме того, были созданы противоречивые примеры с помощью метода FGSM для второй модели и протестированы на первой. В этом случае точность первой модели также уменьшилась, но лишь до 93%, что заметно лучше предыдущего сценария.\n","\n","Атака по переносу с использованием FGSM способна существенно снизить точность модели, особенно если противоречивые примеры были разработаны специально для неё самой."],"metadata":{"id":"3BBHH8rEDlm7"}}]}