# Практическое задание 6: Атака по переносу (Transfer Attack) на модели ИИ


## Цель задания:

Изучить концепцию атаки по переносу, где противоречивые примеры, созданные для одной модели, используются для атаки на другую модель. Это задание требует создания нескольких моделей, генерации противоречивых примеров для одной модели и проверки их на другой модели.

## Задачи:

1. Загрузить несколько моделей, обученных на датасете MNIST.
2. Изучить теоретические основы атаки по переносу.
3. Реализовать атаку FGSM на одну модель и проверить, как противоречивые примеры влияют на другую модель.
4. Оценить точность обеих моделей


## Вывод:
В практической работе было исследовано влияние атаки по переносу, при которой противоречивые примеры, сгенерированные для одной модели, использовались для атаки на другую.

Точность первой модели сократилась с 98% до 12%, что указывает на её высокую уязвимость к данной атаке. В то же время точность второй модели снизилась с 99% до 96%, демонстрируя значительно более устойчивый результат.

Кроме того, были созданы противоречивые примеры с помощью метода FGSM для второй модели и протестированы на первой. В этом случае точность первой модели также уменьшилась, но лишь до 93%, что заметно лучше предыдущего сценария.

Атака по переносу с использованием FGSM способна существенно снизить точность модели, особенно если противоречивые примеры были разработаны специально для неё самой.

## Студент

Сапов Александр Дмитриевич\
Группа ББМО-02-23
