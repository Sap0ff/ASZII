# Практическое задание 4: Атака DeepFool на модели ИИ


## Цель задания:

Изучить атаку DeepFool, которая предназначена для минимальных изменений в изображениях с
целью изменения их классификации. Научиться использовать эту атаку и исследовать влияние
противоречивых примеров на обученные модели.

## Задачи:

1. Загрузить ранее обученную модель на датасете MNIST.
2. Изучить теоретические основы атаки DeepFool.
3. Реализовать атаку DeepFool с помощью фреймворка Foolbox.
4. Оценить точность модели на противоречивых примерах и сравнить с результатами на обычных данных.

## Вывод:

Точность модели машинного обучения при воздействии атаки Deepfool составила менее 0,1%. Этот результат демонстрирует высокую уязвимость системы к целенаправленным вмешательствам. Даже минимальные изменения в исходных изображениях способны кардинально нарушить работу модели.

Подобная хрупкость моделей поднимает серьёзные вопросы о степени их надёжности в реальных условиях, где угрозы могут варьироваться от случайных искажений до сознательных манипуляций.

## Студент

Сапов Александр Дмитриевич\
Группа ББМО-02-23
